{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74690a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.layers import Input, Dense, GRU, LSTM, Bidirectional, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f416608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Coding</th>\n",
       "      <th>Coding_Modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>緊張 する と 呼吸 が 自然 に 早く なっ て たくさん な 考え が 頭 の 中 に ...</td>\n",
       "      <td>sp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>目 を 閉じる と すぐ 眠く なっ て 色んな こと を み て なん か 疲れ が 感じ...</td>\n",
       "      <td>sp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>メタ 認知 的 な 感じ です ね 自分 が 考え て いる ん だ と 分かっ て いる ...</td>\n",
       "      <td>sx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>確か に 食べる の が 早 すぎ まし た 胃 が 重く て しんどかっ た です</td>\n",
       "      <td>sp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>私 は データ 系 の 会社 に 通っ て ます</td>\n",
       "      <td>ss</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>怒り と 悲し み が 伴っ て いる こと に 気づき まし た</td>\n",
       "      <td>sx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>戻っ て き たら 先 妄想 を し て い た と 意識 し まし た また か と いう...</td>\n",
       "      <td>sp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>今 気づき まし た</td>\n",
       "      <td>sp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>人々 が 私 の 目 の 前 に 行き かっ て 何 の 関与 も せ ず に 距離 を と...</td>\n",
       "      <td>sx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>私 は 自分 の 感情 に 小さな 個性 を 持た せ たり と か し た こと が あり ます</td>\n",
       "      <td>sx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text Coding  Coding_Modified\n",
       "90  緊張 する と 呼吸 が 自然 に 早く なっ て たくさん な 考え が 頭 の 中 に ...     sp                0\n",
       "91  目 を 閉じる と すぐ 眠く なっ て 色んな こと を み て なん か 疲れ が 感じ...     sp                0\n",
       "92  メタ 認知 的 な 感じ です ね 自分 が 考え て いる ん だ と 分かっ て いる ...     sx                2\n",
       "93         確か に 食べる の が 早 すぎ まし た 胃 が 重く て しんどかっ た です     sp                0\n",
       "94                           私 は データ 系 の 会社 に 通っ て ます     ss                1\n",
       "95                  怒り と 悲し み が 伴っ て いる こと に 気づき まし た     sx                2\n",
       "96  戻っ て き たら 先 妄想 を し て い た と 意識 し まし た また か と いう...     sp                0\n",
       "97                                         今 気づき まし た     sp                0\n",
       "98  人々 が 私 の 目 の 前 に 行き かっ て 何 の 関与 も せ ず に 距離 を と...     sx                2\n",
       "99  私 は 自分 の 感情 に 小さな 個性 を 持た せ たり と か し た こと が あり ます     sx                2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode ss as 1, sp as 0, sx as 2\n",
    "df1 = pd.read_csv('./data/Data_Modified.csv')\n",
    "df2 = pd.read_csv('./data/Data2_Modified.csv')\n",
    "del df1['Unnamed: 0']\n",
    "del df2['Unnamed: 0']\n",
    "le = preprocessing.LabelEncoder()\n",
    "#df1['Coding'] = le.fit_transform(df1['Coding'])\n",
    "frames = [df1, df2]\n",
    "df = pd.concat(frames)\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['Coding_Modified'] = df['Coding']\n",
    "df['Coding_Modified'] = le.fit_transform(df['Coding_Modified'])\n",
    "df_train = df[0:90]\n",
    "df_test = df[90:100]\n",
    "df_train\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5cdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part should never be ran again!!!\n",
    "#delete_pos = [\"PUNCT\", \"SPACE\", \"SYM\"]\n",
    "\n",
    "#nlp = spacy.load(\"ja_core_news_sm\")\n",
    "\n",
    "#df2 = pd.read_csv('./data/Data2.csv')\n",
    "\n",
    "#def clean_text(sentence):\n",
    "#    '''Clean all irrelavent tokens in the input sentence'''\n",
    "#    doc = nlp(sentence)\n",
    "#    word_list = [str(token) for token in doc if token.pos_ not in delete_pos]\n",
    "#    return ' '.join(word_list)\n",
    "\n",
    "#df2[\"Text\"] = df2[\"Text\"].apply(clean_text)\n",
    "#del df2['Unnamed: 2']\n",
    "#df2.to_csv(\"./data/Data2_Modified.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1fb04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_embedding = WordEmbeddings('ja-crawl')\n",
    "ja_forward_embedding = FlairEmbeddings('ja-forward')\n",
    "ja_backward_embedding = FlairEmbeddings('ja-backward')\n",
    "\n",
    "stacked_embedding = StackedEmbeddings([\n",
    "    ja_embedding,\n",
    "    ja_forward_embedding,\n",
    "    ja_backward_embedding\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2444bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79b5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTrainingData(dataset, batch_size, max_length, num_classes, emb_size):\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    while True:\n",
    "        data = dataset.sample(frac=1)\n",
    "        for index, row in data.iterrows():\n",
    "            my_sent = row['Text']\n",
    "            sentence = Sentence(my_sent)\n",
    "            stacked_embedding.embed(sentence)\n",
    "            x = []\n",
    "            for token in sentence:\n",
    "                x.append(token.embedding.cpu().detach().numpy())\n",
    "                if len(x) == max_length:\n",
    "                    break\n",
    "        \n",
    "            while len(x) < max_length:\n",
    "                x.append(np.zeros(emb_size))\n",
    "                \n",
    "            y = np.zeros(num_classes)\n",
    "            y[row[\"Coding_Modified\"]] = 1\n",
    "            \n",
    "            x_batch.append(x)            \n",
    "            y_batch.append(y)\n",
    "\n",
    "            if len(y_batch) == batch_size:\n",
    "                yield np.array(x_batch), np.array(y_batch)\n",
    "                x_batch = []\n",
    "                y_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3828fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_model(dataset, batch_size, max_len, emb_size, gru_size, num_classes):\n",
    "    sample = Input(batch_shape=(batch_size, max_len, emb_size))\n",
    "    gru_out = Bidirectional(GRU(gru_size, return_sequences=True))(sample)\n",
    "    #lstm_out = Bidirectional(LSTM(gru_size, return_sequences=True))(sample)\n",
    "    gru_out = Flatten()(gru_out)\n",
    "    #lstm_out = Flatten()(lstm_out)\n",
    "    predictions = Dense(num_classes, activation='sigmoid')(gru_out)\n",
    "\n",
    "    model = Model(inputs=sample, outputs=[predictions])\n",
    "    model.compile(optimizer=Adam(),loss='categorical_crossentropy', metrics=[\"acc\"])\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b51914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(1, 17, 4396)]           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (1, 17, 40)               530160    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (1, 680)                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, 3)                    2043      \n",
      "=================================================================\n",
      "Total params: 532,203\n",
      "Trainable params: 532,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 62s 684ms/step - loss: 1.0160 - acc: 0.5357\n",
      "Epoch 2/10\n",
      "46/90 [==============>...............] - ETA: 32s - loss: 0.2670 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "m = declare_model(dataset=df_train, batch_size=1, max_len=17, emb_size=4396, gru_size=20, num_classes=3)\n",
    "gen = generateTrainingData(dataset=df_train, batch_size=1, max_length=17, num_classes=3, emb_size=4396)\n",
    "m.fit(gen, steps_per_epoch=90, epochs=10, max_queue_size=10, workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePredictionData(dataset, batch_size, max_length, num_classes, emb_size):\n",
    "    x_batch = []\n",
    "    while True:\n",
    "        for text in dataset:\n",
    "            my_sent = text\n",
    "            sentence = Sentence(my_sent)\n",
    "            stacked_embedding.embed(sentence)\n",
    "        \n",
    "            x = []\n",
    "            for token in sentence:\n",
    "                x.append(token.embedding.cpu().detach().numpy())\n",
    "                if len(x) == max_length:\n",
    "                    break\n",
    "            while len(x) < max_length:\n",
    "                x.append(np.zeros(emb_size))\n",
    "          \n",
    "            x_batch.append(x)            \n",
    "            if len(x_batch) == batch_size:\n",
    "                yield np.array(x_batch)\n",
    "                \n",
    "                x_batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c66e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_sentences = [\n",
    "#    '私深く考えるタイプじゃないです',\n",
    "#    '今へたへたです',\n",
    "#    '言葉遣いは丁寧であるように厳しく言われてきました'\n",
    "#]\n",
    "#nlp = spacy.load(\"ja_core_news_sm\")\n",
    "#test_sentences_modified = []\n",
    "##stacked_embedding.embed(sentence)\n",
    "#for i in range(3):\n",
    "#    stuff = []\n",
    "#    sentence = nlp(test_sentences[i])\n",
    "#    for token in sentence:\n",
    "#        stuff.append(str(token))\n",
    "#    test_sentences_modified.append(' '.join(stuff))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = []\n",
    "test_results = []\n",
    "for i in range(90, 100):\n",
    "    test_sentences.append(df_test['Text'][i])\n",
    "    test_results.append(df_test['Coding_Modified'][i])\n",
    "test_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generatePredictionData(dataset=test_sentences, batch_size=1, max_length=17, num_classes=3, emb_size=4396)\n",
    "predict = np.argmax(m.predict(gen, steps=10), axis=1)\n",
    "acc = sum([1 for a, b in zip(predict, test_results) if a==b])\n",
    "print(predict)\n",
    "print(acc/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bc6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aceffc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
